{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceType": "datasetVersion",
          "sourceId": 6354265,
          "datasetId": 3659633,
          "databundleVersionId": 6434918
        }
      ],
      "dockerImageVersionId": 31260,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LaraSaads/Projects/blob/main/text_summarization_text_generation_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "path = kagglehub.dataset_download(\"marawanxmamdouh/dialogsum\")"
      ],
      "metadata": {
        "id": "jSsTNJaBrJac",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:50:54.307305Z",
          "iopub.execute_input": "2026-01-29T16:50:54.307749Z",
          "iopub.status.idle": "2026-01-29T16:50:55.110389Z",
          "shell.execute_reply.started": "2026-01-29T16:50:54.307715Z",
          "shell.execute_reply": "2026-01-29T16:50:55.109636Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "train= pd.read_csv(f\"{path}/CSV/train.csv\")\n",
        "val= pd.read_csv(f\"{path}/CSV/validation.csv\")\n",
        "test= pd.read_csv(f\"{path}/CSV/test.csv\")\n"
      ],
      "metadata": {
        "id": "j96q_f4rt1Xp",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:50:55.111838Z",
          "iopub.execute_input": "2026-01-29T16:50:55.112171Z",
          "iopub.status.idle": "2026-01-29T16:50:55.867391Z",
          "shell.execute_reply.started": "2026-01-29T16:50:55.112148Z",
          "shell.execute_reply": "2026-01-29T16:50:55.866809Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "T2ppwF9juCDR",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:50:55.868294Z",
          "iopub.execute_input": "2026-01-29T16:50:55.868634Z",
          "iopub.status.idle": "2026-01-29T16:50:55.892474Z",
          "shell.execute_reply.started": "2026-01-29T16:50:55.868578Z",
          "shell.execute_reply": "2026-01-29T16:50:55.891905Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train.info()\n"
      ],
      "metadata": {
        "id": "pFXSo65Vueds",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:50:55.893299Z",
          "iopub.execute_input": "2026-01-29T16:50:55.893619Z",
          "iopub.status.idle": "2026-01-29T16:50:55.909992Z",
          "shell.execute_reply.started": "2026-01-29T16:50:55.893561Z",
          "shell.execute_reply": "2026-01-29T16:50:55.909321Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train.drop(columns=['id'],inplace=True)"
      ],
      "metadata": {
        "id": "oBAMUREOujha",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:50:55.912262Z",
          "iopub.execute_input": "2026-01-29T16:50:55.912502Z",
          "iopub.status.idle": "2026-01-29T16:50:55.923295Z",
          "shell.execute_reply.started": "2026-01-29T16:50:55.912479Z",
          "shell.execute_reply": "2026-01-29T16:50:55.922553Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "\n",
        "    # Remove speaker tags like #Person1#\n",
        "    text = re.sub(r\"#Person\\d+#\", \"\", text)\n",
        "\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remove URLs (if any)\n",
        "    text = re.sub(r\"http\\S+|www\\S+\", \"\", text)\n",
        "\n",
        "    # Remove special characters (keep basic punctuation)\n",
        "    text = re.sub(r\"[^a-zA-Z0-9.,!?'\\s]\", \"\", text)\n",
        "\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
        "\n",
        "    return text\n"
      ],
      "metadata": {
        "id": "D_8qv5Sxu5mo",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:50:55.924250Z",
          "iopub.execute_input": "2026-01-29T16:50:55.924572Z",
          "iopub.status.idle": "2026-01-29T16:50:55.929515Z",
          "shell.execute_reply.started": "2026-01-29T16:50:55.924551Z",
          "shell.execute_reply": "2026-01-29T16:50:55.928945Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train[\"dialogue_clean\"] = train[\"dialogue\"].apply(clean_text)\n",
        "train[\"summary_clean\"]  = train[\"summary\"].apply(clean_text)\n",
        "train[\"topic_clean\"]    = train[\"topic\"].apply(clean_text)\n",
        "val[\"dialogue_clean\"] = val[\"dialogue\"].apply(clean_text)\n",
        "val[\"summary_clean\"]  = val[\"summary\"].apply(clean_text)\n",
        "val[\"topic_clean\"]    = val[\"topic\"].apply(clean_text)\n",
        "test[\"dialogue_clean\"] = test[\"dialogue\"].apply(clean_text)\n",
        "test[\"summary_clean\"]  = test[\"summary\"].apply(clean_text)\n",
        "test[\"topic_clean\"]    = test[\"topic\"].apply(clean_text)\n"
      ],
      "metadata": {
        "id": "cesEDfi6vJKI",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:50:55.930394Z",
          "iopub.execute_input": "2026-01-29T16:50:55.930683Z",
          "iopub.status.idle": "2026-01-29T16:50:57.001070Z",
          "shell.execute_reply.started": "2026-01-29T16:50:55.930652Z",
          "shell.execute_reply": "2026-01-29T16:50:57.000244Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train"
      ],
      "metadata": {
        "id": "zO9yzJGGvVOg",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:50:57.002050Z",
          "iopub.execute_input": "2026-01-29T16:50:57.002344Z",
          "iopub.status.idle": "2026-01-29T16:50:57.012336Z",
          "shell.execute_reply.started": "2026-01-29T16:50:57.002313Z",
          "shell.execute_reply": "2026-01-29T16:50:57.011649Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "val[\"dialogue_clean\"] = val[\"dialogue\"].apply(clean_text)\n",
        "val[\"summary_clean\"]  = val[\"summary\"].apply(clean_text)\n",
        "test[\"dialogue_clean\"] = test[\"dialogue\"].apply(clean_text)\n",
        "test[\"summary_clean\"]  = test[\"summary\"].apply(clean_text)"
      ],
      "metadata": {
        "id": "9W8m5yH7-IRo",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:50:57.014021Z",
          "iopub.execute_input": "2026-01-29T16:50:57.014863Z",
          "iopub.status.idle": "2026-01-29T16:50:57.170631Z",
          "shell.execute_reply.started": "2026-01-29T16:50:57.014810Z",
          "shell.execute_reply": "2026-01-29T16:50:57.169836Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data = train[[\"dialogue_clean\", \"summary_clean\"]]\n",
        "val_data = val[[\"dialogue_clean\", \"summary_clean\"]]\n"
      ],
      "metadata": {
        "id": "D35StxxYx5of",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:50:57.171862Z",
          "iopub.execute_input": "2026-01-29T16:50:57.172144Z",
          "iopub.status.idle": "2026-01-29T16:50:57.178706Z",
          "shell.execute_reply.started": "2026-01-29T16:50:57.172111Z",
          "shell.execute_reply": "2026-01-29T16:50:57.178018Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_data.rename(columns={\n",
        "    \"dialogue_clean\": \"text\",\n",
        "    \"summary_clean\": \"summary\"\n",
        "})\n",
        "\n",
        "val_data = val_data.rename(columns={\n",
        "    \"dialogue_clean\": \"text\",\n",
        "    \"summary_clean\": \"summary\"\n",
        "})\n"
      ],
      "metadata": {
        "id": "7dpTSuHoy0En",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:50:57.179631Z",
          "iopub.execute_input": "2026-01-29T16:50:57.180115Z",
          "iopub.status.idle": "2026-01-29T16:50:57.195055Z",
          "shell.execute_reply.started": "2026-01-29T16:50:57.180091Z",
          "shell.execute_reply": "2026-01-29T16:50:57.194520Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BartTokenizer, BartForConditionalGeneration\n",
        "\n",
        "model_name = \"facebook/bart-large-cnn\"\n",
        "\n",
        "tokenizer = BartTokenizer.from_pretrained(model_name)\n",
        "model = BartForConditionalGeneration.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "aW3qeLQozL6U",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:50:57.195785Z",
          "iopub.execute_input": "2026-01-29T16:50:57.195967Z",
          "iopub.status.idle": "2026-01-29T16:51:28.662478Z",
          "shell.execute_reply.started": "2026-01-29T16:50:57.195948Z",
          "shell.execute_reply": "2026-01-29T16:51:28.661556Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(batch):\n",
        "    model_inputs = tokenizer(\n",
        "        batch[\"text\"],\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        labels = tokenizer(\n",
        "            batch[\"summary\"],\n",
        "            max_length=128,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\"\n",
        "        )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n"
      ],
      "metadata": {
        "id": "slSXOhrpz7YL",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:51:28.663895Z",
          "iopub.execute_input": "2026-01-29T16:51:28.664698Z",
          "iopub.status.idle": "2026-01-29T16:51:28.670796Z",
          "shell.execute_reply.started": "2026-01-29T16:51:28.664650Z",
          "shell.execute_reply": "2026-01-29T16:51:28.669985Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "hf_train = Dataset.from_pandas(train_data)\n",
        "hf_val   = Dataset.from_pandas(val_data)\n",
        "\n",
        "hf_train = hf_train.map(tokenize_function, batched=True, remove_columns=[\"text\", \"summary\"])\n",
        "hf_val   = hf_val.map(tokenize_function, batched=True, remove_columns=[\"text\", \"summary\"])\n"
      ],
      "metadata": {
        "id": "O80CrFlv0Aib",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:51:28.674183Z",
          "iopub.execute_input": "2026-01-29T16:51:28.674444Z",
          "iopub.status.idle": "2026-01-29T16:51:53.089085Z",
          "shell.execute_reply.started": "2026-01-29T16:51:28.674420Z",
          "shell.execute_reply": "2026-01-29T16:51:53.088513Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./dialogsum_bart\",\n",
        "    eval_strategy=\"steps\",\n",
        "    per_device_train_batch_size=1,\n",
        "    per_device_eval_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=2,\n",
        "    fp16=True,\n",
        "    logging_steps=100,\n",
        "    save_steps=1000,\n",
        "    save_total_limit=2,\n",
        "    report_to=\"none\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "5DrPrP040WWL",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:51:53.089981Z",
          "iopub.execute_input": "2026-01-29T16:51:53.090541Z",
          "iopub.status.idle": "2026-01-29T16:51:55.494528Z",
          "shell.execute_reply.started": "2026-01-29T16:51:53.090515Z",
          "shell.execute_reply": "2026-01-29T16:51:55.493741Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=hf_train,\n",
        "    eval_dataset=hf_val,\n",
        "    tokenizer=tokenizer\n",
        ")\n"
      ],
      "metadata": {
        "id": "trebW6Q40mxr",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:51:55.495570Z",
          "iopub.execute_input": "2026-01-29T16:51:55.495895Z",
          "iopub.status.idle": "2026-01-29T16:51:56.032865Z",
          "shell.execute_reply.started": "2026-01-29T16:51:55.495862Z",
          "shell.execute_reply": "2026-01-29T16:51:56.032282Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "qJy9FL8F0poM",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T16:51:56.033786Z",
          "iopub.execute_input": "2026-01-29T16:51:56.034249Z",
          "iopub.status.idle": "2026-01-29T19:38:50.257900Z",
          "shell.execute_reply.started": "2026-01-29T16:51:56.034203Z",
          "shell.execute_reply": "2026-01-29T19:38:50.257023Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate rouge_score\n",
        "import evaluate\n",
        "\n",
        "rouge = evaluate.load(\"rouge\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "    labels = [[(l if l != -100 else tokenizer.pad_token_id) for l in label] for label in labels]\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    return rouge.compute(predictions=decoded_preds, references=decoded_labels)"
      ],
      "metadata": {
        "id": "HW6PbzdoNxRo",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:06:04.264307Z",
          "iopub.status.idle": "2026-01-29T20:06:04.264543Z",
          "shell.execute_reply.started": "2026-01-29T20:06:04.264434Z",
          "shell.execute_reply": "2026-01-29T20:06:04.264448Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()\n"
      ],
      "metadata": {
        "id": "5GP9Sr66ONHa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:07:39.988906Z",
          "iopub.execute_input": "2026-01-29T20:07:39.989215Z",
          "iopub.status.idle": "2026-01-29T20:08:42.592189Z",
          "shell.execute_reply.started": "2026-01-29T20:07:39.989189Z",
          "shell.execute_reply": "2026-01-29T20:08:42.591636Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"dialogsum_model\")\n",
        "tokenizer.save_pretrained(\"dialogsum_model\")\n",
        "!zip -r dialogsum_bart.zip /kaggle/working/dialogsum_bart\n",
        "\n"
      ],
      "metadata": {
        "id": "Opxzm3o_OZn-",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:15:30.461531Z",
          "iopub.execute_input": "2026-01-29T20:15:30.461934Z",
          "iopub.status.idle": "2026-01-29T20:23:13.612403Z",
          "shell.execute_reply.started": "2026-01-29T20:15:30.461898Z",
          "shell.execute_reply": "2026-01-29T20:23:13.611228Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_dialogue(dialogue):\n",
        "    inputs = tokenizer(\n",
        "        dialogue,\n",
        "        return_tensors=\"pt\",\n",
        "        max_length=512,\n",
        "        truncation=True\n",
        "    )\n",
        "\n",
        "    inputs = {name: tensor.to(model.device) for name, tensor in inputs.items()}\n",
        "\n",
        "    summary_ids = model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=150,\n",
        "        num_beams=4,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "7HLySq_QO5MW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:09:41.093938Z",
          "iopub.execute_input": "2026-01-29T20:09:41.094548Z",
          "iopub.status.idle": "2026-01-29T20:09:41.100186Z",
          "shell.execute_reply.started": "2026-01-29T20:09:41.094511Z",
          "shell.execute_reply": "2026-01-29T20:09:41.099477Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "summarize_dialogue(\n",
        "    \"hi, mr. smith. i'm doctor hawkins. why are you here today?\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "X3htPa4YO-vG",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:09:44.720664Z",
          "iopub.execute_input": "2026-01-29T20:09:44.721251Z",
          "iopub.status.idle": "2026-01-29T20:09:45.523390Z",
          "shell.execute_reply.started": "2026-01-29T20:09:44.721221Z",
          "shell.execute_reply": "2026-01-29T20:09:45.522662Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "topic_train = train[[\"dialogue_clean\", \"topic_clean\"]].rename(\n",
        "    columns={\n",
        "        \"dialogue_clean\": \"text\",\n",
        "        \"topic_clean\": \"topic\"\n",
        "    }\n",
        ")\n",
        "\n",
        "topic_val = val[[\"dialogue_clean\", \"topic_clean\"]].rename(\n",
        "    columns={\n",
        "        \"dialogue_clean\": \"text\",\n",
        "        \"topic_clean\": \"topic\"\n",
        "    }\n",
        ")\n"
      ],
      "metadata": {
        "id": "C5HDg74Q-TbP",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T19:40:17.581396Z",
          "iopub.execute_input": "2026-01-29T19:40:17.581697Z",
          "iopub.status.idle": "2026-01-29T19:40:17.595990Z",
          "shell.execute_reply.started": "2026-01-29T19:40:17.581673Z",
          "shell.execute_reply": "2026-01-29T19:40:17.595221Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "t5_model_name = \"t5-small\"\n",
        "\n",
        "t5_tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
        "t5_model = T5ForConditionalGeneration.from_pretrained(t5_model_name)\n"
      ],
      "metadata": {
        "id": "diQ41NX9-2X4",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T19:40:17.597100Z",
          "iopub.execute_input": "2026-01-29T19:40:17.597366Z",
          "iopub.status.idle": "2026-01-29T19:40:50.740987Z",
          "shell.execute_reply.started": "2026-01-29T19:40:17.597343Z",
          "shell.execute_reply": "2026-01-29T19:40:50.740175Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_topic(batch):\n",
        "    inputs = [\"generate topic: \" + x for x in batch[\"text\"]]\n",
        "\n",
        "    model_inputs = t5_tokenizer(\n",
        "        inputs,\n",
        "        max_length=512,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    labels = t5_tokenizer(\n",
        "        batch[\"topic\"],\n",
        "        max_length=16,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\"\n",
        "    )\n",
        "\n",
        "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
        "    return model_inputs\n"
      ],
      "metadata": {
        "id": "ycjTARMo_JwX",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T19:40:50.742052Z",
          "iopub.execute_input": "2026-01-29T19:40:50.742367Z",
          "iopub.status.idle": "2026-01-29T19:40:50.746992Z",
          "shell.execute_reply.started": "2026-01-29T19:40:50.742333Z",
          "shell.execute_reply": "2026-01-29T19:40:50.746296Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "hf_topic_train = Dataset.from_pandas(topic_train)\n",
        "hf_topic_val   = Dataset.from_pandas(topic_val)\n",
        "\n",
        "hf_topic_train = hf_topic_train.map(tokenize_topic, batched=True, remove_columns=[\"text\", \"topic\"])\n",
        "hf_topic_val   = hf_topic_val.map(tokenize_topic, batched=True, remove_columns=[\"text\", \"topic\"])\n"
      ],
      "metadata": {
        "id": "guHiRyjQ_Nxa",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T19:40:50.748027Z",
          "iopub.execute_input": "2026-01-29T19:40:50.748353Z",
          "iopub.status.idle": "2026-01-29T19:41:01.128469Z",
          "shell.execute_reply.started": "2026-01-29T19:40:50.748322Z",
          "shell.execute_reply": "2026-01-29T19:41:01.127776Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "topic_args = TrainingArguments(\n",
        "    output_dir=\"./dialogsum_t5_topic\",\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=3,\n",
        "    learning_rate=3e-4,\n",
        "    fp16=True,\n",
        "    logging_steps=100,\n",
        "    save_total_limit=2,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "topic_trainer = Trainer(\n",
        "    model=t5_model,\n",
        "    args=topic_args,\n",
        "    train_dataset=hf_topic_train,\n",
        "    eval_dataset=hf_topic_val,\n",
        "    tokenizer=t5_tokenizer\n",
        ")\n",
        "\n",
        "topic_trainer.train()\n"
      ],
      "metadata": {
        "id": "A9fYpUbx_SdJ",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T19:41:01.129491Z",
          "iopub.execute_input": "2026-01-29T19:41:01.130126Z",
          "iopub.status.idle": "2026-01-29T20:06:03.852666Z",
          "shell.execute_reply.started": "2026-01-29T19:41:01.130099Z",
          "shell.execute_reply": "2026-01-29T20:06:03.851919Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "t5_model.save_pretrained(\"dialogsum_topic_model\")\n",
        "t5_tokenizer.save_pretrained(\"dialogsum_topic_model\")\n",
        "\n"
      ],
      "metadata": {
        "id": "y_TpP-PbzWCU",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:24:33.348676Z",
          "iopub.execute_input": "2026-01-29T20:24:33.349472Z",
          "iopub.status.idle": "2026-01-29T20:24:33.957090Z",
          "shell.execute_reply.started": "2026-01-29T20:24:33.349426Z",
          "shell.execute_reply": "2026-01-29T20:24:33.956288Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /kaggle/working/\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:24:38.057025Z",
          "iopub.execute_input": "2026-01-29T20:24:38.057829Z",
          "iopub.status.idle": "2026-01-29T20:24:38.241362Z",
          "shell.execute_reply.started": "2026-01-29T20:24:38.057796Z",
          "shell.execute_reply": "2026-01-29T20:24:38.240640Z"
        },
        "id": "yy2uZmwhHcL5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "bart_model = BartForConditionalGeneration.from_pretrained(\n",
        "    \"/kaggle/working/dialogsum_model\"\n",
        ").to(device)\n",
        "\n",
        "bart_tokenizer = BartTokenizer.from_pretrained(\n",
        "    \"/kaggle/working/dialogsum_model\"\n",
        ")\n",
        "\n",
        "bart_model.config.pad_token_id = bart_tokenizer.pad_token_id\n",
        "bart_model.eval()\n"
      ],
      "metadata": {
        "id": "ekhdIVrqaLch",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:26:55.884013Z",
          "iopub.execute_input": "2026-01-29T20:26:55.884376Z",
          "iopub.status.idle": "2026-01-29T20:26:56.746191Z",
          "shell.execute_reply.started": "2026-01-29T20:26:55.884346Z",
          "shell.execute_reply": "2026-01-29T20:26:56.745537Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(dialogue):\n",
        "    inputs = bart_tokenizer(\n",
        "        dialogue,\n",
        "        return_tensors=\"pt\",\n",
        "        truncation=True,\n",
        "        max_length=1024\n",
        "    ).to(device)\n",
        "\n",
        "    summary_ids = bart_model.generate(\n",
        "        inputs[\"input_ids\"],\n",
        "        max_length=60,\n",
        "        min_length=20,\n",
        "        num_beams=4,\n",
        "        length_penalty=2.0,\n",
        "        early_stopping=True\n",
        "    )\n",
        "\n",
        "    return bart_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"
      ],
      "metadata": {
        "id": "8MpIcvU-WEj0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:47:55.311220Z",
          "iopub.execute_input": "2026-01-29T20:47:55.311999Z",
          "iopub.status.idle": "2026-01-29T20:47:55.317394Z",
          "shell.execute_reply.started": "2026-01-29T20:47:55.311961Z",
          "shell.execute_reply": "2026-01-29T20:47:55.316540Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_summary(\n",
        "    \"hi, mr. smith. i'm doctor hawkins. why are you here today?\"\n",
        "))"
      ],
      "metadata": {
        "id": "pZv5dACWcTh_",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:47:58.858602Z",
          "iopub.execute_input": "2026-01-29T20:47:58.859270Z",
          "iopub.status.idle": "2026-01-29T20:47:59.214040Z",
          "shell.execute_reply.started": "2026-01-29T20:47:58.859240Z",
          "shell.execute_reply": "2026-01-29T20:47:59.213233Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio pyngrok\n"
      ],
      "metadata": {
        "id": "oRTuJgz1WRUK",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:34:10.267092Z",
          "iopub.execute_input": "2026-01-29T20:34:10.267384Z",
          "iopub.status.idle": "2026-01-29T20:34:17.251464Z",
          "shell.execute_reply.started": "2026-01-29T20:34:10.267358Z",
          "shell.execute_reply": "2026-01-29T20:34:17.250656Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chat(dialogue):\n",
        "    summary = generate_summary(dialogue)\n",
        "    topic = generate_topic(dialogue)\n",
        "    return summary, topic\n"
      ],
      "metadata": {
        "id": "1p5IcBefWbHE",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:48:15.030654Z",
          "iopub.execute_input": "2026-01-29T20:48:15.031328Z",
          "iopub.status.idle": "2026-01-29T20:48:15.035176Z",
          "shell.execute_reply.started": "2026-01-29T20:48:15.031299Z",
          "shell.execute_reply": "2026-01-29T20:48:15.034399Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(\n",
        "    fn=chat,\n",
        "    inputs=gr.Textbox(lines=6, label=\"Enter Dialogue\"),\n",
        "    outputs=[\n",
        "        gr.Textbox(label=\"Generated Summary\"),\n",
        "        gr.Textbox(label=\"Generated Topic\")\n",
        "    ],\n",
        "    title=\"Text Summarization and Generation\",\n",
        "    description=\"Transformer-based dialogue summarization and topic generation\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "qVklRA91Wkxq",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:48:24.430204Z",
          "iopub.execute_input": "2026-01-29T20:48:24.430860Z",
          "iopub.status.idle": "2026-01-29T20:48:24.615449Z",
          "shell.execute_reply.started": "2026-01-29T20:48:24.430829Z",
          "shell.execute_reply": "2026-01-29T20:48:24.614816Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!killall ngrok"
      ],
      "metadata": {
        "id": "CStL9JDGbKW0",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:48:38.891984Z",
          "iopub.execute_input": "2026-01-29T20:48:38.892318Z",
          "iopub.status.idle": "2026-01-29T20:48:39.086662Z",
          "shell.execute_reply.started": "2026-01-29T20:48:38.892288Z",
          "shell.execute_reply": "2026-01-29T20:48:39.085841Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "interface.launch(\n",
        "    share=True,\n",
        "    server_port=7861  # optional\n",
        ")\n"
      ],
      "metadata": {
        "id": "UhH3mlbWWzgW",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:51:08.952618Z",
          "iopub.execute_input": "2026-01-29T20:51:08.953366Z",
          "iopub.status.idle": "2026-01-29T20:51:09.832428Z",
          "shell.execute_reply.started": "2026-01-29T20:51:08.953333Z",
          "shell.execute_reply": "2026-01-29T20:51:09.831778Z"
        }
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r dialogsum_bart.zip /kaggle/working/dialogsum_bart\n",
        "!zip -r dialogsum_t5_topic.zip /kaggle/working/dialogsum_t5_topic\n"
      ],
      "metadata": {
        "id": "TXWfl7y7uLn6",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2026-01-29T20:53:04.322905Z",
          "iopub.execute_input": "2026-01-29T20:53:04.323567Z"
        }
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}